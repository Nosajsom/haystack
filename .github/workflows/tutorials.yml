name: Tutorials

on:
  workflow_dispatch:  # Activate this workflow manually
  push:
    branches:
      - master
    paths:
      - '**/*.py'
      - '**/*.cfg'
      - '**/*.toml'
      - '**/*.ipynb'
  pull_request:
    # branches:
    #   - master
    # paths:
    #   - '**/*.py'
    #   - '**/*.cfg'
    #   - '**/*.toml'
    #   - '**/*.ipynb'

jobs:

  # notebooks-matrix:
  #   runs-on: ubuntu-latest
  #   steps:
  #     - uses: actions/checkout@v2
  #     - id: notebooks-matrix
  #       run: echo "::set-output name=matrix::$(find tutorials/ -name "*.ipynb" | jq -SR . | jq -cs .)"
  #   outputs:
  #     matrix: ${{ steps.notebooks-matrix.outputs.matrix }}


  # scripts-matrix:
  #   runs-on: ubuntu-latest
  #   steps:
  #     - uses: actions/checkout@v2
  #     - id: scripts-matrix
  #       run: echo "::set-output name=matrix::$(find tutorials/ -name "*.py" | jq -SR . | jq -cs .)"
  #   outputs:
  #     matrix: ${{ steps.scripts-matrix.outputs.matrix }}


  # notebooks:
  #   runs-on: ubuntu-latest
  #   strategy:
  #     matrix:
  #       notebook-path: #${{fromJson(needs.notebooks-matrix.outputs.matrix)}}
  #       script-path:
  #         # This lasts about 40 mins
  #         - [
  #             "tutorials/Tutorial1_Basic_QA_Pipeline.ipynb",                         #  2 mins
  #             # Tutorial 2 takes over a hour withouth GPU
  #             "tutorials/Tutorial3_Basic_QA_Pipeline_without_Elasticsearch.ipynb",   #  3 mins
  #             "tutorials/Tutorial4_FAQ_style_QA.ipynb",                              #  2 mins
  #             "tutorials/Tutorial5_Evaluation.ipynb",                                # 12 mins
  #             "tutorials/TTutorial6_Better_Retrieval_via_DPR.ipynb",                 # 12 mins
  #             "tutorials/Tutorial7_RAG_Generator.ipynb"                              #  6 mins
  #           ]
  #         - [
  #             "tutorials/Tutorial8_Preprocessing.ipynb",     # 2 mins
  #             # Tutorial 9 takes over a hour without GPU
  #             "tutorials/Tutorial10_Knowledge_Graph.ipynb",  # ? mins
  #             "tutorials/Tutorial11_Pipelines.ipynb",        # ? mins
  #             "tutorials/Tutorial12_LFQA.ipynb"              # 13 mins
  #           ]
  #         - [
  #             # Tutorial 13 takes over a hour without GPU
  #             "tutorials/Tutorial14_Query_Classifier.ipynb",                    # ? mins
  #             "tutorials/Tutorial15_TableQA.ipynb",                             # 10 mins
  #             "tutorials/Tutorial16_Document_Classifier_at_Index_Time.ipynb ",  # ? mins
  #           ]
  #     fail-fast: false

  #   steps:
  #   - uses: actions/checkout@v2
  #   - run: echo "date=$(date +'%Y-%m-%d')" >> $GITHUB_ENV

  #   - name: Set up Python 3.7
  #     uses: actions/setup-python@v2
  #     with:
  #       python-version: 3.7

  #   - name: Install pdftotext
  #     run: wget --no-check-certificate https://dl.xpdfreader.com/xpdf-tools-linux-4.04.tar.gz && tar -xvf xpdf-tools-linux-4.04.tar.gz && sudo cp xpdf-tools-linux-4.04/bin64/pdftotext /usr/local/bin

  #   - name: Run notebook
  #     run: |
  #       pip install ipython nbformat
  #       sudo ${{ env.pythonLocation }}/bin/ipython -c "%run ${{ matrix.notebook-path }}"


  tutorials:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        script-path:
           # 2 is very long
        - "1_Basic_QA_Pipeline \
           3_Basic_QA_Pipeline_without_Elasticsearch \
           4_FAQ_style_QA \
           5_Evaluation"

        - "6_Better_Retrieval_via_DPR \
           7_RAG_Generator"

          # 9 is very long
        - "8_Preprocessing \
           10_Knowledge_Graph"

        - "11_Pipelines \
           12_LFQA"

          # 13 is very long
        - "14_Query_Classifier \
           15_TableQA \
           16_Document_Classifier_at_Index_Time"

    steps:
    - uses: actions/checkout@v2
    - run: echo "date=$(date +'%Y-%m-%d')" >> $GITHUB_ENV

    - name: Set up Python 3.7
      uses: actions/setup-python@v2
      with:
        python-version: 3.7

    - name: Cache Python
      uses: actions/cache@v2
      with:
        path: ${{ env.pythonLocation }}
        key: linux-${{ env.date }}-${{ hashFiles('**/setup.py') }}-${{ hashFiles('**/setup.cfg') }}-${{ hashFiles('**/pyproject.toml') }}

    - name: Run Elasticsearch
      run: docker run -d -p 9200:9200 -e "discovery.type=single-node" -e "ES_JAVA_OPTS=-Xms128m -Xmx128m" elasticsearch:7.9.2

    - name: Run Apache Tika
      run: docker run -d -p 9998:9998 -e "TIKA_CHILD_JAVA_OPTS=-JXms128m" -e "TIKA_CHILD_JAVA_OPTS=-JXmx128m" apache/tika:1.24.1

    - name: Run GraphDB
      run: docker run -d -p 7200:7200 --name graphdb-instance-tutorial docker-registry.ontotext.com/graphdb-free:9.4.1-adoptopenjdk11

    - name: Install pdftotext
      run: wget --no-check-certificate https://dl.xpdfreader.com/xpdf-tools-linux-4.04.tar.gz && tar -xvf xpdf-tools-linux-4.04.tar.gz && sudo cp xpdf-tools-linux-4.04/bin64/pdftotext /usr/local/bin

    - name: Install graphviz
      run: sudo apt install libgraphviz-dev graphviz

    # Haystack needs to be reinstalled at this stage to make sure the current commit's version is the one getting tested.
    # The cache can last way longer than a specific action's run, so older Haystack version could be carried over.
    - name: Reinstall Haystack
      run: |
        pip install --upgrade pip
        pip install .[all]
        pip install torch-scatter -f https://data.pyg.org/whl/torch-1.11.0+cpu.html
        pip install pygraphviz
        pip install ipython nbformat

    - name: Reduce GoT dataset
      run: |
        # Cache the GoT data
        mkdir data
        mkdir data/tutorials
        cd data/tutorials
        wget https://s3.eu-central-1.amazonaws.com/deepset.ai-farm-qa/datasets/documents/wiki_gameofthrones_txt1.zip -q
        unzip wiki_gameofthrones_txt1.zip
        rm wiki_gameofthrones_txt1.zip
        find . -name '[1-9][0-9][0-9]_*.txt' -delete
        find . -name '[0-9]_*.txt' -delete
        cd ../../


    - name: Run tutorials
      run: |
        export LAUNCH_GRAPHDB=0      # See tut 10 - GraphDB is already running in CI
        export TIKA_LOG_PATH=$PWD    # Avoid permission denied errors while importing tika
        set -e                       # Fails on any error in the following loop

        for script in ${{ matrix.script-path }}; do

          # These ones don't use GoT data
          if [[ "$script" != "4_FAQ_style_QA" ]] && [[ "$script" != "8_Preprocessing" ]]  && [[ "$script" != "10_Knowledge_Graph" ]]; then

            # Copy the reduced GoT data into a folder named after the tutorial 
            # to trigger the caching mechanism of `fetch_archive_from_http`
            split_on_underscore=(${script//_/ })
            cp -r data/tutorials data/tutorial${split_on_underscore[0]}

          fi
        
          echo ""
          echo "#############################################################"
          echo "  Running $script ..."
          echo "#############################################################"
          echo ""
          echo "====== Tutorial$script.py ===================="
          python tutorials/Tutorial$script.py
          echo ""
          echo "====== Tutorial$script.ipynb ================="
          sudo ${{ env.pythonLocation }}/bin/ipython -c "%run tutorials/Tutorial$script.ipynb"
        done
